// é‡æ–°è®­ç»ƒ Connect4 AlphaZero - ä¼˜åŒ–ç‰ˆæœ¬

use gomoku::az_eval::{evaluate, Player};
use gomoku::az_trainer::AlphaZeroTrainer;
use std::convert::TryFrom;

fn main() {
    println!("ğŸš€ AlphaZero Connect4 é‡æ–°è®­ç»ƒ\n");
    println!("ç›®æ ‡ï¼šä¿®å¤policy biasé—®é¢˜ï¼Œè®­ç»ƒä¸€ä¸ªçœŸæ­£æœ‰ç”¨çš„æ¨¡å‹\n");

    // ä¼˜åŒ–çš„è¶…å‚æ•°
    let num_filters = 128;       // ä½¿ç”¨128æ»¤æ³¢å™¨ï¼ˆä¸ä¹‹å‰ä¸€è‡´ï¼‰
    let learning_rate = 0.002;   // ç¨å¾®æé«˜å­¦ä¹ ç‡
    let replay_buffer_size = 5000; // å¢å¤§å›æ”¾ç¼“å†²åŒº
    let num_mcts_simulations = 200; // å¢åŠ MCTSæ¨¡æ‹Ÿæ¬¡æ•°ä»¥è·å¾—æ›´å¥½çš„è®­ç»ƒæ•°æ®

    let num_iterations = 30;     // å‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œä½†æ¯æ¬¡è´¨é‡æ›´é«˜
    let games_per_iteration = 30; // æ¯æ¬¡è¿­ä»£ç”Ÿæˆæ›´å¤šæ•°æ®
    let train_batches = 100;     // å¢åŠ è®­ç»ƒæ‰¹æ¬¡
    let batch_size = 64;         // æ‰¹æ¬¡å¤§å°
    let temperature = 1.0;       // æ¸©åº¦å‚æ•°

    println!("ğŸ“‹ è®­ç»ƒé…ç½®:");
    println!("  ç½‘ç»œ: ResNet-10 with {} filters", num_filters);
    println!("  MCTSæ¨¡æ‹Ÿæ¬¡æ•°: {}", num_mcts_simulations);
    println!("  å­¦ä¹ ç‡: {}", learning_rate);
    println!("  å›æ”¾ç¼“å†²åŒº: {}", replay_buffer_size);
    println!("  è®­ç»ƒè¿­ä»£: {}", num_iterations);
    println!("  æ¯è½®è‡ªå¯¹å¼ˆ: {} å±€", games_per_iteration);
    println!("  æ¯è½®è®­ç»ƒæ‰¹æ¬¡: {}", train_batches);
    println!("  æ‰¹æ¬¡å¤§å°: {}\n", batch_size);

    let mut trainer = AlphaZeroTrainer::new(
        num_filters,
        learning_rate,
        replay_buffer_size,
        num_mcts_simulations,
    );

    // è¯„ä¼°åˆå§‹æ¨¡å‹
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  åˆå§‹è¯„ä¼°ï¼ˆéšæœºåˆå§‹åŒ–çš„ç½‘ç»œï¼‰              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    let initial_win_rate = quick_evaluate(&trainer, "åˆå§‹");

    let mut best_win_rate = initial_win_rate;
    let mut best_model_iteration = 0;

    // è®­ç»ƒå¾ªç¯
    for iteration in 0..num_iterations {
        println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        println!("ğŸ“Š è¿­ä»£ {}/{}", iteration + 1, num_iterations);
        println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

        // 1. ç”Ÿæˆè‡ªå¯¹å¼ˆæ•°æ®
        println!("\nğŸ® é˜¶æ®µ1: ç”Ÿæˆè‡ªå¯¹å¼ˆæ•°æ®");
        trainer.generate_self_play_data(games_per_iteration, temperature);

        // 2. è®­ç»ƒç½‘ç»œ
        println!("\nğŸ§  é˜¶æ®µ2: è®­ç»ƒç¥ç»ç½‘ç»œ");
        trainer.train(batch_size, train_batches);

        // 3. ä¿å­˜æ£€æŸ¥ç‚¹
        let checkpoint_path = format!("connect4_resnet_iter_{}.pt", iteration + 1);
        if let Err(e) = trainer.save_model(&checkpoint_path) {
            eprintln!("âš ï¸  ä¿å­˜æ¨¡å‹å¤±è´¥: {}", e);
        } else {
            println!("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {}", checkpoint_path);
        }

        // 4. æ¯5æ¬¡è¿­ä»£è¿›è¡Œè¯¦ç»†è¯„ä¼°
        if (iteration + 1) % 5 == 0 {
            println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
            println!("â•‘  è¯¦ç»†è¯„ä¼° - è¿­ä»£ {}                        â•‘", iteration + 1);
            println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
            
            let win_rate = detailed_evaluate(&trainer, iteration + 1);
            
            // ä¿å­˜æœ€ä½³æ¨¡å‹
            if win_rate > best_win_rate {
                best_win_rate = win_rate;
                best_model_iteration = iteration + 1;
                let best_path = "connect4_resnet_best.pt";
                if let Ok(_) = trainer.save_model(best_path) {
                    println!("ğŸ† ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {} (èƒœç‡: {:.1}%)", best_path, best_win_rate * 100.0);
                }
            }
        } else {
            // å¿«é€Ÿè¯„ä¼°
            quick_evaluate(&trainer, &format!("è¿­ä»£{}", iteration + 1));
        }
    }

    // æœ€ç»ˆè¯„ä¼°
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  æœ€ç»ˆè¯„ä¼°                                  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    detailed_evaluate(&trainer, num_iterations);

    // ä¿å­˜æœ€ç»ˆæ¨¡å‹
    let final_path = "connect4_resnet_final.pt";
    if let Ok(_) = trainer.save_model(final_path) {
        println!("\nğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {}", final_path);
    }

    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ‰ è®­ç»ƒå®Œæˆï¼");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("æœ€ä½³æ¨¡å‹: è¿­ä»£ {} (èƒœç‡ vs éšæœº: {:.1}%)", best_model_iteration, best_win_rate * 100.0);
    println!("æ¨¡å‹æ–‡ä»¶: connect4_resnet_best.pt");
}

/// å¿«é€Ÿè¯„ä¼°ï¼ˆå°‘é‡å¯¹å±€ï¼‰
fn quick_evaluate(trainer: &AlphaZeroTrainer, label: &str) -> f32 {
    let alphazero = Player::AlphaZero {
        net: &trainer.trainer.net,
        simulations: 50,
    };

    let random_player = Player::Random;

    print!("\nğŸ“Š {} vs éšæœºç©å®¶ (5å±€å¿«é€Ÿæµ‹è¯•)...", label);
    let stats = evaluate(&alphazero, &random_player, 5, false);
    let win_rate = stats.player1_winrate();
    println!(" èƒœç‡: {:.1}%", win_rate * 100.0);
    
    win_rate
}

/// è¯¦ç»†è¯„ä¼°ï¼ˆæ›´å¤šå¯¹å±€ï¼‰
fn detailed_evaluate(trainer: &AlphaZeroTrainer, iteration: usize) -> f32 {
    let alphazero = Player::AlphaZero {
        net: &trainer.trainer.net,
        simulations: 50,
    };

    let random_player = Player::Random;
    let pure_mcts = Player::PureMCTS { simulations: 50 };

    println!("\nğŸ“Š è¿­ä»£{} vs éšæœºç©å®¶ (20å±€)", iteration);
    let stats1 = evaluate(&alphazero, &random_player, 20, false);
    let win_rate_random = stats1.player1_winrate();
    println!("  èƒœç‡: {:.1}%", win_rate_random * 100.0);
    println!("  è¯¦æƒ…: {} èƒœ, {} è´Ÿ, {} å¹³", 
             stats1.player1_wins, stats1.player2_wins, stats1.draws);

    println!("\nğŸ“Š è¿­ä»£{} vs çº¯MCTS(50æ¨¡æ‹Ÿ) (20å±€)", iteration);
    let stats2 = evaluate(&alphazero, &pure_mcts, 20, false);
    let win_rate_mcts = stats2.player1_winrate();
    println!("  èƒœç‡: {:.1}%", win_rate_mcts * 100.0);
    println!("  è¯¦æƒ…: {} èƒœ, {} è´Ÿ, {} å¹³", 
             stats2.player1_wins, stats2.player2_wins, stats2.draws);

    // æ£€æŸ¥policy bias
    check_policy_bias(trainer);

    win_rate_random
}

/// æ£€æŸ¥policyåå·®
fn check_policy_bias(trainer: &AlphaZeroTrainer) {
    use gomoku::connect4::Connect4;
    use tch::Tensor;

    println!("\nğŸ” æ£€æŸ¥ç©ºæ£‹ç›˜çš„policyè¾“å‡º:");
    
    let game = Connect4::new();
    let board_tensor = game.to_tensor();
    
    // è½¬æ¢ä¸ºTensor [1, 3, 6, 7]
    let device = trainer.trainer.net.device();
    let tensor = Tensor::from_slice(&board_tensor)
        .view([1, 3, 6, 7])
        .to(device);
    
    let (policy_logits, value) = tch::no_grad(|| {
        trainer.trainer.net.predict(&tensor)
    });
    
    let policy_probs = policy_logits.softmax(-1, tch::Kind::Float);
    let probs: Vec<f32> = Vec::try_from(policy_probs.squeeze()).unwrap();
    let value_f: f32 = value.double_value(&[]) as f32;
    
    println!("  Valueé¢„æµ‹: {:.4}", value_f);
    println!("  Policyæ¦‚ç‡åˆ†å¸ƒ:");
    for (i, prob) in probs.iter().enumerate() {
        let bar = "â–ˆ".repeat((prob * 50.0) as usize);
        println!("    Col {}: {:.4} {}", i, prob, bar);
    }
    
    // æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾åå·®
    let max_prob = probs.iter().cloned().fold(0.0f32, f32::max);
    let avg_prob = probs.iter().sum::<f32>() / probs.len() as f32;
    
    if max_prob > 0.3 {
        println!("  âš ï¸  æ£€æµ‹åˆ°åå·®ï¼šcolumn {} çš„æ¦‚ç‡è¿‡é«˜ ({:.1}%)", 
                 probs.iter().position(|&p| p == max_prob).unwrap(), 
                 max_prob * 100.0);
    } else if (max_prob - avg_prob).abs() < 0.05 {
        println!("  âœ… Policyåˆ†å¸ƒç›¸å¯¹å‡åŒ€ï¼ˆå¥½ç°è±¡ï¼‰");
    }
}
